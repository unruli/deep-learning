{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is an exercise in the [Intro to Deep Learning](https://www.kaggle.com/learn/intro-to-deep-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/deep-neural-networks).**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In the tutorial, I saw how to build deep neural networks by stacking layers inside a `Sequential` model. By adding an *activation function* after the hidden layers, we gave the network the ability to learn more complex (non-linear) relationships in the data.\n",
    "\n",
    "In these exercises, l built a neural network with several hidden layers and then explore some activation functions beyond ReLU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:49:07.472897Z",
     "iopub.status.busy": "2021-10-14T22:49:07.472548Z",
     "iopub.status.idle": "2021-10-14T22:49:12.925878Z",
     "shell.execute_reply": "2021-10-14T22:49:12.924718Z",
     "shell.execute_reply.started": "2021-10-14T22:49:07.472804Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "\n",
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning_intro.ex2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the *Concrete* dataset, your task is to predict the compressive strength of concrete manufactured according to various recipes.\n",
    "\n",
    "Run the next code cell without changes to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:49:18.761723Z",
     "iopub.status.busy": "2021-10-14T22:49:18.761257Z",
     "iopub.status.idle": "2021-10-14T22:49:18.813258Z",
     "shell.execute_reply": "2021-10-14T22:49:18.812204Z",
     "shell.execute_reply.started": "2021-10-14T22:49:18.761690Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "concrete = pd.read_csv('../input/dl-course-data/concrete.csv')\n",
    "concrete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Input Shape #\n",
    "\n",
    "The target for this task is the column `'CompressiveStrength'`. The remaining columns are the features we'll use as inputs.\n",
    "\n",
    "What would be the input shape for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:50:22.349925Z",
     "iopub.status.busy": "2021-10-14T22:50:22.349594Z",
     "iopub.status.idle": "2021-10-14T22:50:22.357625Z",
     "shell.execute_reply": "2021-10-14T22:50:22.357072Z",
     "shell.execute_reply.started": "2021-10-14T22:50:22.349892Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape = [8]\n",
    "\n",
    "\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:50:43.226910Z",
     "iopub.status.busy": "2021-10-14T22:50:43.226621Z",
     "iopub.status.idle": "2021-10-14T22:50:43.237802Z",
     "shell.execute_reply": "2021-10-14T22:50:43.237165Z",
     "shell.execute_reply.started": "2021-10-14T22:50:43.226879Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "q_1.hint()\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Define a Model with Hidden Layers #\n",
    "\n",
    "Now  I created a model with three hidden layers, each having 512 units and the ReLU activation.  I was sure to include an output layer of one unit and no activation, and also `input_shape` as an argument to the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:54:02.443467Z",
     "iopub.status.busy": "2021-10-14T22:54:02.443161Z",
     "iopub.status.idle": "2021-10-14T22:54:03.764453Z",
     "shell.execute_reply": "2021-10-14T22:54:03.763285Z",
     "shell.execute_reply.started": "2021-10-14T22:54:02.443438Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),    \n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:52:14.568935Z",
     "iopub.status.busy": "2021-10-14T22:52:14.568505Z",
     "iopub.status.idle": "2021-10-14T22:52:14.590273Z",
     "shell.execute_reply": "2021-10-14T22:52:14.589107Z",
     "shell.execute_reply.started": "2021-10-14T22:52:14.568885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution codeq_2.hint()\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Activation Layers #\n",
    "\n",
    "Let's explore activations functions some.\n",
    "\n",
    "The usual way of attaching an activation function to a `Dense` layer is to include it as part of the definition with the `activation` argument. Sometimes though you'll want to put some other layer between the `Dense` layer and its activation function. (We'll see an example of this in Lesson 5 with *batch normalization*.) In this case, we can define the activation in its own `Activation` layer, like so:\n",
    "\n",
    "```\n",
    "layers.Dense(units=8),\n",
    "layers.Activation('relu')\n",
    "```\n",
    "\n",
    "This is completely equivalent to the ordinary way: `layers.Dense(units=8, activation='relu')`.\n",
    "\n",
    "Rewrite the following model so that each activation is in its own `Activation` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:59:22.314201Z",
     "iopub.status.busy": "2021-10-14T22:59:22.313879Z",
     "iopub.status.idle": "2021-10-14T22:59:22.362161Z",
     "shell.execute_reply": "2021-10-14T22:59:22.361188Z",
     "shell.execute_reply.started": "2021-10-14T22:59:22.314169Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE: rewrite this to use activation layers\n",
    "model =keras.Sequential([\n",
    "    layers.Dense(32, input_shape=[8]),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(32),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "# Check your answer\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T22:58:21.903834Z",
     "iopub.status.busy": "2021-10-14T22:58:21.903499Z",
     "iopub.status.idle": "2021-10-14T22:58:21.913346Z",
     "shell.execute_reply": "2021-10-14T22:58:21.912417Z",
     "shell.execute_reply.started": "2021-10-14T22:58:21.903804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#q_3.hint()\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Alternatives to ReLU #\n",
    "\n",
    "There is a whole family of variants of the `'relu'` activation -- `'elu'`, `'selu'`, and `'swish'`, among others -- all of which you can use in Keras. Sometimes one activation will perform better than another on a given task, so you could consider experimenting with activations as you develop a model. The ReLU activation tends to do well on most problems, so it's a good one to start with.\n",
    "\n",
    "Let's look at the graphs of some of these. Change the activation from `'relu'` to one of the others named above. Then run the cell to see the graph. (Check out the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/activations) for more ideas.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T23:06:10.717581Z",
     "iopub.status.busy": "2021-10-14T23:06:10.717243Z",
     "iopub.status.idle": "2021-10-14T23:06:10.977122Z",
     "shell.execute_reply": "2021-10-14T23:06:10.976355Z",
     "shell.execute_reply.started": "2021-10-14T23:06:10.717541Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Change 'relu' to 'elu', 'selu', 'swish'... or something else\n",
    "activation_layer = layers.Activation('relu')\n",
    "\n",
    "x = tf.linspace(-3.0, 3.0, 100)\n",
    "y = activation_layer(x) # once created, a layer is callable just like a function\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-3, 3)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Going #\n",
    "\n",
    "Now move on to Lesson 3 and [**learn how to train neural networks**](https://www.kaggle.com/ryanholbrook/stochastic-gradient-descent) with stochastic gradient descent."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
